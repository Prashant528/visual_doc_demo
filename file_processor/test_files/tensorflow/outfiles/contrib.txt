['Contributing guidelines', 'Pull Request Checklist', 'Before sending your pull requests, make sure you do the following:', '- Read the contributing guidelines.', '- Read the Code of Conduct.', '- Ensure you have signed the\nContributor License Agreement (CLA).', '- Check if your changes are consistent with the\nguidelines.', '- Changes are consistent with the Coding Style.', '- Run the unit tests.', 'How to become a contributor and submit your own code', 'Screen Shot 2022-08-30 at 7 27 04 PM', 'Typical Pull Request Workflow -', '1. New PR', '- As a contributor, you submit a New PR on GitHub.', '- We inspect every incoming PR and add certain labels to the PR such as size:,\ncomp: etc.  At this stage we check if the PR is valid and meets certain\nquality requirements. For example, we check if the CLA is signed, PR has\nsufficient description, if applicable unit tests are added, if it is a\nreasonable contribution (meaning it is not a single liner cosmetic PR).', '2. Valid?', '- If the PR passes all the quality checks then we go ahead and assign a\nreviewer.', "- If the PR didn't meet the validation criteria, we request for additional\nchanges to be made to PR to pass quality checks and send it back or on a\nrare occasion we may reject it.", '3. Review', '- For a valid PR, reviewer (person familiar with the code/functionality)\nchecks if the PR looks good or needs additional changes.', '- If all looks good, the reviewer will approve the PR.', '- If a change is needed, the contributor is requested to make the suggested\nchange.', '- You make the change and submit it for the review again.', '- This cycle repeats itself until the PR gets approved.', '- Note: As a friendly reminder, we may reach out to you if the PR is awaiting\nyour response for more than 2 weeks.', '4. Approved', '- Once the PR is approved, it gets kokoro:force-run label applied and it\ninitiates CI/CD tests.', "- We can't move forward if these tests fail.", '- In such situations, we may request you to make further changes to your PR\nfor the tests to pass.', '- Once the tests pass, we now bring all the code into the internal code base,\nusing a job called "copybara".', '5. Copy to Google Internal codebase and run internal CI', '- Once the PR is in the Google codebase, we make sure it integrates well with\nits dependencies and the rest of the system.', '- Rarely, If the tests fail at this stage, we cannot merge the code.', '- If needed, we may come to you to make some changes. At times, it may not be\nyou, it may be us who may have hit a snag. Please be patient while we work\nto fix this.', '- Once the internal tests pass, we go ahead and merge the code internally as\nwell as externally on GitHub.', 'In a graphical form, the entire lifetime of a PR looks like', 'image', 'Contributor License Agreements', "We'd love to accept your patches! Before we can take them, we have to jump a couple of legal hurdles.", 'Please fill out either the individual or corporate Contributor License Agreement (CLA).', "- If you are an individual writing original source code and you're sure you own the intellectual property, then you'll need to sign an individual CLA.", "- If you work for a company that wants to allow you to contribute your work, then you'll need to sign a corporate CLA.", "Follow either of the two links above to access the appropriate CLA and instructions for how to sign and return it. Once we receive it, we'll be able to accept your pull requests.", 'NOTE: Only original source code from you and other people that have signed the CLA can be accepted into the main repository.', 'Contributing code', 'If you have improvements to TensorFlow, send us your pull requests! For those\njust getting started, GitHub has a\nhow-to.', 'TensorFlow team members will be assigned to review your pull requests. Once the\npull requests are approved and pass continuous integration checks, a TensorFlow\nteam member will apply ready to pull label to your change. This means we are\nworking on getting your pull request submitted to our internal repository. After\nthe change has been submitted internally, your pull request will be merged\nautomatically on GitHub.', 'If you want to contribute, start working through the TensorFlow codebase,\nnavigate to the\nGitHub "issues" tab and start\nlooking through interesting issues. If you are not sure of where to start, then\nstart by trying one of the smaller/easier issues here i.e.\nissues with the "good first issue" label\nand then take a look at the\nissues with the "contributions welcome" label.\nThese are issues that we believe are particularly well suited for outside\ncontributions, often because we probably won\'t get to them right now. If you\ndecide to start on an issue, leave a comment so that other people know that\nyou\'re working on it. If you want to help out, but not alone, use the issue\ncomment thread to coordinate.', 'Contribution guidelines and standards', 'Before sending your pull request for\nreview,\nmake sure your changes are consistent with the guidelines and follow the\nTensorFlow coding style.', 'General guidelines and philosophy for contribution', '- Include unit tests when you contribute new features, as they help to a)\nprove that your code works correctly, and b) guard against future breaking\nchanges to lower the maintenance cost.', '- Bug fixes also generally require unit tests, because the presence of bugs\nusually indicates insufficient test coverage.', '- Keep API compatibility in mind when you change code in core TensorFlow,\ne.g., code in\ntensorflow/core\nand\ntensorflow/python.\nTensorFlow has passed version 1.0 and hence cannot make\nnon-backward-compatible API changes without a major release. Reviewers of\nyour pull request will comment on any API compatibility issues\nfollowing API review practices.', '- When you contribute a new feature to TensorFlow, the maintenance burden is\n(by default) transferred to the TensorFlow team. This means that the benefit\nof the contribution must be compared against the cost of maintaining the\nfeature.', '- Full new features (e.g., a new op implementing a cutting-edge algorithm)\ntypically will live in\ntensorflow/addons to get some\nairtime before a decision is made regarding whether they are to be migrated\nto the core.', '- As every PR requires several CPU/GPU hours of CI testing, we discourage\nsubmitting PRs to fix one typo, one warning,etc. We recommend fixing the\nsame issue at the file level at least (e.g.: fix all typos in a file, fix\nall compiler warnings in a file, etc.)', '- Tests should follow the\ntesting best practices\nguide.', 'License', 'Include a license at the top of new files.', '- C/C++ license example', '- Python license example', '- Java license example', '- Go license example', '- Bash license example', '- JavaScript/TypeScript license example', 'Bazel BUILD files also need to include a license section, e.g.,\nBUILD example.', 'C++ coding style', 'Changes to TensorFlow C++ code should conform to\nGoogle C++ Style Guide.', 'Use clang-tidy to check your C/C++ changes. To install clang-tidy on ubuntu:16.04, do:', 'apt-get install -y clang-tidy', 'You can check a C/C++ file by doing:', 'clang-format <my_cc_file> --style=google > /tmp/my_cc_file.cc\ndiff <my_cc_file> /tmp/my_cc_file.cc', 'Python coding style', 'Changes to TensorFlow Python code should conform to\nGoogle Python Style Guide', "Use pylint to check your Python changes. To install pylint and check a file\nwith pylint against TensorFlow's custom style definition:", 'pip install pylint\npylint --rcfile=tensorflow/tools/ci_build/pylintrc myfile.py', 'Note pylint --rcfile=tensorflow/tools/ci_build/pylintrc should run from the\ntop level tensorflow directory.', 'Coding style for other languages', '- Google Java Style Guide', '- Google JavaScript Style Guide', '- Google Shell Style Guide', '- Google Objective-C Style Guide', 'Running sanity check', 'If you have Docker installed on your system, you can perform a sanity check on\nyour changes by running the command:', 'tensorflow/tools/ci_build/ci_build.sh CPU tensorflow/tools/ci_build/ci_sanity.sh', 'This will catch most license, Python coding style and BUILD file issues that\nmay exist in your changes.', 'Running unit tests', 'There are two ways to run TensorFlow unit tests.', '1.  Using tools and libraries installed directly on your system.', 'Refer to the\nCPU-only developer Dockerfile\nand\nGPU developer Dockerfile\nfor the required packages. Alternatively, use the said\ntensorflow/build Docker images\n(tensorflow/tensorflow:devel and tensorflow/tensorflow:devel-gpu are no\nlonger supported for) development. Use TF SIG Build Dockerfiles in\ndevelopment to avoid installing the packages directly on your system (in\nwhich case remember to change the directory from /root to /tensorflow\nonce you get into the running container so bazel can find the tensorflow\nworkspace).', 'you can do this by using the following command. As an example-', 'docker run -it --rm -v $PWD:/tmp -w /tmp tensorflow/build:2.15-python3.10', 'Once you have the packages installed, you can run a specific unit test in\nbazel by doing as follows:', 'export flags="--config=opt -k"', 'If the tests are to be run on the GPU, add CUDA paths to LD_LIBRARY_PATH and\nadd the cuda option flag', 'export LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH"\nexport flags="--config=opt --config=cuda -k"', 'For example, to run all tests under tensorflow/python, do:', 'bazel test ${flags} //tensorflow/python/...', 'For a single component e.g. softmax op:', 'bazel test ${flags} tensorflow/python/kernel_tests/nn_ops:softmax_op_test', 'For a single/parameterized test e.g. test_capture_variables in\ntensorflow/python/saved_model/load_test.py:', '(Requires python>=3.7)', 'bazel test ${flags} //tensorflow/python/saved_model:load_test --test_filter=*LoadTest.test_capture_variables*', 'Note: You can add --test_sharding_strategy=disabled to the flags to\ndisable the sharding so that all the test outputs are in one file. However,\nit may slow down the tests for not running in parallel and may cause the\ntest to timeout but it could be useful when you need to execute a single\ntest or more in general your filtered/selected tests have a very low\nexecution time and the sharding\ncould create an overhead on the test execution.', "2.  Using Docker and TensorFlow's CI scripts.", '# Install Docker first, then this will build and run cpu tests\ntensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...', 'See\nTensorFlow Builds\nfor details.', 'Running doctest for testable docstring', 'There are two ways to test the code in the docstring locally:', "1.  If you are only changing the docstring of a class/function/method, then you\ncan test it by passing that file's path to\ntf_doctest.py.\nFor example:", 'python tf_doctest.py --file=<file_path>', "This will run it using your installed version of TensorFlow. To be sure\nyou're running the same code that you're testing:", '- Use an up to date tf-nightly\npip install -U tf-nightly', "- Rebase your pull request onto a recent pull from\nTensorFlow's master branch.", '2.  If you are changing the code and the docstring of a class/function/method,\nthen you will need to\nbuild TensorFlow from source.\nOnce you are setup to build from source, you can run the tests:', 'bazel run //tensorflow/tools/docs:tf_doctest', 'or', 'bazel run //tensorflow/tools/docs:tf_doctest -- --module=ops.array_ops', 'The --module is relative to tensorflow.python.', 'Debug builds', 'When building Tensorflow, passing', '--config=dbg to Bazel will build with debugging information and without\noptimizations, allowing you to use GDB or other debuggers to debug C++ code. For\nexample, you can build the pip package with debugging information by running:', 'bazel build --config=dbg //tensorflow/tools/pip_package:build_pip_package', "TensorFlow kernels and TensorFlow's dependencies are still not built with\ndebugging information with --config=dbg, as issues occur on Linux if\nthere is too much debug info (see this GitHub\nissue for context). If\nyou want to debug a kernel, you can compile specific files with -g using the", '--per_file_copt bazel option. For example, if you want to debug the Identity\nop, which are in files starting with identity_op, you can run', 'bazel build --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g //tensorflow/tools/pip_package:build_pip_package', 'Note that the --config=dbg option is not officially supported.']