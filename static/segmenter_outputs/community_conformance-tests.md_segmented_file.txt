title: "Contributing to Kubernetes"
weight: 4
description: |
An entrypoint to getting started with contributing to the Kubernetes project.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Kubernetes is open source, but many of the people working on it do so as their day job. In order to avoid forcing people to be "at work" effectively 24/7, we want to establish some semi-formal protocols around development. Hopefully, these rules make things go more smoothly. If you find that this is not the case, please complain loudly. As a potential contributor, your changes and ideas are welcome at any hour of the day or night, weekdays, weekends, and holidays. Please do not ever hesitate to ask a question or send a pull request. Check out our [community guiding principles](/contributors/guide/expectations.md#code-review) on how to create great code as a big group. Beginner focused information can be found below in  and . For quick reference on contributor resources, we have a handy [contributor cheatsheet](./contributor-cheatsheet/).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Communication
It is best to contact your [SIG](first-contribution.md#learn-about-sigs) for issues related to the SIG's topic. Your SIG will be able to help you much more quickly than a general question would. For general questions and troubleshooting, use the [standard lines of communication](/communication/README.md) and work through the [troubleshooting guide](https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

GitHub workflow
To check out code to work on, please refer to [the GitHub Workflow Guide](./github-workflow.md). - [Kubernetes-specific github workflow](pull-requests.md#the-testing-and-merge-workflow). That document is comprehensive and detailed, for purposes of a typical pull request we will cover the initial and simple use case here:

Opening a Pull Request
Pull requests are often called a "PR". Kubernetes generally follows the standard [github pull request] (https://help.github.com/articles/about-pull-requests/) process, but there is a layer of additional kubernetes specific (and sometimes SIG specific) differences: The first difference you'll see is that a bot will begin applying structured labels to your PR. The bot may also make some helpful suggestions for commands to run in your PR to facilitate review. These `/command` options can be entered in comments to trigger auto-labeling and notifications. Refer to its [command reference documentation](https://go.k8s.io/bot-commands).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

- Not having correctly signed the CLA ahead of your first PR. See the [CLA page](/CLA.md) for troubleshooting help, in some cases you might need to file a ticket with the CNCF to resolve a CLA problem.
- Finding the right SIG or reviewer(s) for the PR (see section) and following any SIG or repository specific contributing guidelines (see [Learn about SIGs](first-contribution.md#learn-about-sigs) section)
- Dealing with test cases which fail on your PR, unrelated to the changes you introduce (see [Test Flakes](/contributors/devel/sig-testing/flaky-tests.md))
- Not following [scalability good practices](scalability-good-practices.md)
- Include mentions (like @person) and [keywords] (https://help.github.com/en/articles/closing-issues-using-keywords) which could close the issue (like fixes #xxxx) in commit messages.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Code Review
For a brief description of the importance of code review, please read [On Code Review](/contributors/guide/expectations.md#code-review). There are two aspects of code review: giving and receiving.
- Follow the project [coding conventions](coding-conventions.md)
- Write [good commit messages] (https://chris.beams.io/posts/git-commit/)
- Break large changes into a logical series of smaller patches which individually make easily understandable changes, and in aggregate solve a broader issue
- Label PRs with appropriate SIGs and reviewers: to do this read the messages the bot sends you to guide you through the PR process

Reviewers, the people giving the review, are highly encouraged to revisit the [Code of Conduct](/code-of-conduct.md) as well as [community expectations](./expectations.md#expectations-of-reviewers-review-latency) and must go above and beyond to promote a collaborative, respectful community.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

- Is the idea behind the contribution sound?
- Is the contribution architected correctly?
- Is the contribution polished?

Note: if your pull request isn't getting enough attention, you can use the [#pr-reviews] (https://kubernetes.slack.com/messages/pr-reviews) channel on Slack to get help finding reviewers.
- Write clear and meaningful git commit messages.
- If the PR will completely fix a specific issue, include `fixes #123` in the PR body (where 123 is the specific issue number the PR will fix. This will automatically close the issue when the PR is merged.
- Make sure you don't include `@mentions` or `fixes` keywords in your git commit messages. These should be included in the PR body instead.
- When you make a PR for small change (such as fixing a typo, style change, or grammar fix), please squash your commits so that we can maintain a cleaner git history.
- Make sure you include a clear and detailed PR description explaining the reasons for the changes, and ensuring there is sufficient information for the reviewer to understand your PR.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

- Additional Readings:
  - [chris.beams.io/posts/git-commit/](https://chris.beams.io/posts/git-commit/)
  - [github.com/blog/1506-closing-issues-via-pull-requests ] (https://github.com/blog/1506-closing-issues-via-pull-requests)
  - [davidwalsh.name/squash-commits-git ](https://davidwalsh.name/squash-commits-git)
  - [https://mtlynch.io/code-review-love/](https://mtlynch.io/code-review-love/)

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Testing
Testing is the responsibility of all contributors and is in part owned by all SIGs, but is also coordinated by [sig-testing](/sig-testing). Refer to the [Testing Guide](/contributors/devel/sig-testing/testing.md) for more information. There are multiple types of tests.
- Unit: These confirm that a particular function behaves as intended. Golang includes a native ability for unit testing via the [testing](https://golang.org/pkg/testing/) package. Unit test source code can be found adjacent to the corresponding source code within a given package. For example: functions defined in [kubernetes/cmd/kubeadm/app/util/version.go] (https://git.k8s.io/kubernetes/cmd/kubeadm/app/util/version.go) will have unit tests in [kubernetes/cmd/kubeadm/app/util/version_test.go] (https://git.k8s.io/kubernetes/cmd/kubeadm/app/util/version_test.go). These are easily run locally by any developer on any OS.
- Integration: These tests cover interactions of package components or interactions between kubernetes components and some other non-kubernetes system resource (eg: etcd). An example would be testing whether a piece of code can correctly store data to or retrieve data from etcd. Integration tests are stored in [kubernetes/test/integration/] (https://git.k8s.io/kubernetes/test/integration). Running these can require the developer set up additional functionality on their development system.
- End-to-end ("e2e"): These are broad tests of overall system behavior and coherence. These are more complicated as they require a functional kubernetes cluster built from the sources to be tested. A separate [document detailing e2e testing](/contributors/devel/sig-testing/e2e-tests.md) and test cases themselves can be found in [kubernetes/test/e2e/] (https://git.k8s.io/kubernetes/test/e2e).
- Conformance: These are a set of testcases, currently a subset of the integration/e2e tests, that the Architecture SIG has approved to define the core set of interoperable features that all Kubernetes deployments must support. For more information on Conformance tests please see the [Conformance Testing](/contributors/devel/sig-architecture/conformance-tests.md) Document.

Continuous integration will run these tests either as pre-submits on PRs, post-submits against master/release branches, or both. The results appear on [testgrid](https://testgrid.k8s.io). sig-testing is responsible for that official infrastructure and CI. The associated automation is tracked in the [test-infra repo](https://git.k8s.io/test-infra). If you're looking to run e2e tests on your own infrastructure, [kubetest] (https://git.k8s.io/test-infra/kubetest) is the mechanism.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

- [Security Release Page] (https://git.k8s.io/security/security-release-process.md) - outlines the procedures for the handling of security issues.
- [Security and Disclosure Information](https://kubernetes.io/docs/reference/issues-security/security/) - check this page if you wish to report a security vulnerability.
- [Contributing to Documentation](https://kubernetes.io/editdocs/)

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Issues Management or Triage
Have you ever noticed the total number of [open issues] (https://issues.k8s.io)? Helping to manage or triage these open issues can be a great contribution and a great opportunity to learn about the various areas of the project. Triaging is the word we use to describe the process of adding multiple types of descriptive labels to GitHub issues, in order to speed up routing issues to the right folks. Refer to the [Issue Triage Guidelines](/contributors/guide/issue-triage.md) for more information.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Conformance Testing in Kubernetes
The Kubernetes Conformance test suite is a subset of e2e tests that SIG Architecture has approved to define the core set of interoperable features that all conformant Kubernetes clusters must support. The tests verify that the expected behavior works as a user might encounter it in the wild.
- Contributors write and submit e2e tests, to be approved by owning SIGs
- Tests are proven to meet the by review and by accumulation of data on flakiness and reliability
- A follow up PR is submitted to

NB:
- The desired set of conformant behaviors is not adequately expressed by the current set of e2e tests, as such this document is currently intended to guide us in the addition of new e2e tests than can fill this gap
- This document currently focuses solely on the requirements for GA, non-optional features or APIs. The list of requirements will be refined over time to the point where it as concrete and complete as possible.
- There are currently conformance tests that violate some of the requirements (e.g., require privileged access), we will be categorizing these tests and deciding what to do once we have a better understanding of the situation
- Once we resolve the above issues, we plan on identifying the appropriate areas to relax requirements to allow for the concept of conformance Profiles that cover optional or additional behaviors

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Conformance Test Requirements
Conformance tests currently test only GA, non-optional features or APIs.
- it tests only GA, non-optional features or APIs (e.g., no alpha or beta endpoints, no feature flags required, no deprecated features)
- it does not require direct access to kubelet's API to pass (nor does it require indirect access via the API server node proxy endpoint); it MAY use the kubelet API for debugging purposes upon failure
- it works for all providers (e.g., no `SkipIfProviderIs`/`SkipUnlessProviderIs` calls)
- it limits itself to capabilities exposed via APIs (e.g., does not require root on nodes, access to raw network interfaces) and does not require write access to system namespaces (like kube-system)
- it works without access to the public internet (short of whatever is required to pre-pull images for conformance tests)
- it works without non-standard filesystem permissions granted to pods
- it does not rely on any binaries that would not be required for the linux kernel or kubelet to run (e.g., can't rely on git)
- where possible, it does not depend on outputs that change based on OS (nslookup, ping, chmod, ls)
- any container images used within the test support all architectures for which kubernetes releases are built
- it passes against the appropriate versions of kubernetes as spelled out in the
- it is stable and runs consistently (e.g., no flakes), and has been running for at least two weeks
- new conformance tests or updates to conformance tests for additional scenarios are only allowed before code freeze dates set by the release team to allow enough soak time of the changes and gives folks a chance to kick the tires either in the community CI or their own infrastructure to make sure the tests are robust
- it has a name that is a literal string

Examples of features which are not currently eligible for conformance tests:
- node/platform-reliant features, eg: multiple disk mounts, GPUs, high density, etc.
- optional features, eg: policy enforcement
- cloud-provider-specific features, eg: GCE monitoring, S3 Bucketing, etc.
- anything that requires a non-default admission plugin
- features that are pending deprecation, eg: componentstatus
- any endpoints that are operational tools, rather than application-oriented, should not be part of conformance, eg: apiserver logs.

Conformance tests are intended to be stable and backwards compatible according to the standard API deprecation policies. Therefore any test that relies on specific output that is not subject to the deprecation policy cannot be promoted to conformance.
- If a test depends on events it is recommended to change the test to use an informer pattern and watch specific resource changes instead.
- An exception to this is tests that generates synthetic events themselves to verify that the API is capable of being exercised
- If the test is checking for specific conditions or reasons, it is considered overly specific and it is recommended to simply look for pass/failure criteria where possible, and output the condition/reason for debugging purposes only.
- tests may need to create or set objects or fields that are alpha or beta that bypass policies that are not yet GA, but which may reasonably be enabled on a conformant cluster (e.g., pod security policy, non-GA scheduler annotations)

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Windows & Linux Considerations
Windows node support is an optional but stable feature as of Kubernetes 1.14. This means that it is not required by conformance testing. Nonetheless, it's important to verify that the behavior of Windows nodes match the behaviors tested in the conformance suite as much as possible. To that end, a large number of conformance tests are already included in Windows testing. You can see what tests are already passing by looking at TestGrid for results of Windows tests running on [Azure](https://testgrid.k8s.io/sig-windows#aks-engine-azure-windows-master) and [GCE] (https://testgrid.k8s.io/sig-windows#gce-windows-master)). Tests may be scheduled for any PR with the bot command `/test pull-kubernetes-e2e-aks-engine-azure-windows`.

- Make sure tests that are already passing remain passing. If new OS-specific functionality is added, it should be in a new test.
- Ensure that new tests covering Linux-specific functionality are tagged with `[LinuxOnly]` (see: [Kinds of Tests] (https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md#kinds-of-tests)).
- Give future reviewers a reference to an active issue or documentation clarifying why a test cannot run on Windows.
- Rely only on container images that already have a multi-architecture manifest including Windows versions, or have been ported by SIG-Windows (see [kubernetes-sigs/windows-testing/images] (https://github.com/kubernetes-sigs/windows-testing/tree/master/images)).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

- Do not depend on any functionality that is different or not available on Windows. The full list is available in the Windows Kubernetes docs under [api](https://kubernetes.io/docs/setup/windows/intro-windows-in-kubernetes/#api).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

A brief summary is included here as a starting point. If the docs are insufficient or there are more questions, please contact #SIG-Windows on Slack to get another reviewer.

- Container Images
  - Watch out for image names hardcoded into test cases or YAML files. These are often Linux-only. Instead, they should be adding to or using existing images from [tests/utils/image/manifest.go] (https://github.com/kubernetes/kubernetes/blob/master/test/utils/image/manifest.go). This allows the container registry to be configured to one containing Windows images, and also supports testing on clusters with no internet access using a private registry. Multi-arch images supporting Windows are also acceptable.

- Container Options & Actions
  - Pod SecurityContext is set. Most of the fields are Linux specific, and any field set in the Pod's SecurityContext will result in the Pod not being able to spawn or not work as intended.
  - Privileged containers are not supported. Containers are always isolated.
  - Windows uses job objects or Hyper-V for pod isolation and resource controls, not CGroups. These are managed implicitly by Docker or ContainerD, not by the kubelet. Do not check properties of CGroups as pass/fail criteria.
  - Running Linux-specific commands are not likely to work. Some commands may work using a Windows [busybox] (https://github.com/kubernetes-sigs/windows-testing/tree/master/images/busybox) container. The paths of these binaries may differ from Linux, so it's best to rely on `PATH` rather than using Linux-specific paths such as `/usr/bin/nc`. As an alternative, you can use commands in the cross-platform [agnhost] (https://github.com/kubernetes/kubernetes/tree/master/test/images/agnhost) image which is designed to return the same results regardless of OS.

- Storage
  - File permissions cannot be set on volumes. Tests using `DefaultMode` or `Mode` and checking the resulting permissions will fail.
  - Only NTFS volumes are supported. Volume mounts specifying other filesystems (ext4, xfs) or mediums (memory) are not supported
  - Bidirectional mount propagation, specifically propagating mounts from a container to host, does not work.

- Networking
  - Pods set `HostNetwork=true`. For Windows, this can only be enabled for Windows Privileged Containers. In other cases, the Pod will not start.
  - Network and DNS settings must be passed through CNI. Windows does not use `/etc/resolv.conf`, so tests should not rely on reading that file to check DNS settings.
  - If you want to check network settings such as dns search lists, please use [agnhost] (https://github.com/kubernetes/kubernetes/tree/master/test/images/agnhost) to output needed data from the container.
  - Windows treats all DNS lookups with a `.` to be FQDN, not PQDN. For example `kubernetes` will resolve as a PQDN, but `kubernetes.default` will be resolved as a FQDN and fail.
  - ICMP only works between pods on the same network, and are not routable to external networks. TCP/UDP are routable.
  - Windows containers do not support IPv6.

The existing tests which are affected by one of those criteria are tagged with `[LinuxOnly]` (see: [Kinds of Tests] (https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md#kinds-of-tests).

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Conformance Test Version Skew Policy
As each new release of Kubernetes provides new functionality, the subset of tests necessary to demonstrate conformance grows with each release. Conformance is thus considered versioned, with the same backwards compatibility guarantees as laid out in the [kubernetes versioning policy] (https://git.k8s.io/design-proposals-archive/release/versioning.md#supported-releases-and-component-skew)

To quote:
For example, a v1.3 master should work with v1.1, v1.2, and v1.3 nodes, and should work with v1.2, v1.3, and v1.4 clients.

Conformance tests for a given version should be run off of the release branch that corresponds to that version. Thus `v1.2` conformance tests would be run from the head of the `release-1.2` branch.

For example, suppose we're in the midst of developing kubernetes v1.3. Clusters with the following versions must pass conformance tests built from the following branches:

cluster version
master
release-1.3
release-1.2
release-1.1
v1.3.0-alpha
yes
yes
yes
no
v1.2.x
no
no
yes
yes
v1.1.x
no
no
no
yes

Running Conformance Tests
Conformance tests are designed to be run even when there is no cloud provider configured. Conformance tests must be able to be run against clusters that have not been created with `test-infra/kubetest`, just provide a kubeconfig with the appropriate endpoint and credentials.

Running Conformance Tests With [KinD] (https://kind.sigs.k8s.io/)
- Work in your kubernetes branch, preferably in the default go src location: `$GOPATH/src/k8s.io/kubernetes`
```
kind build node-image
```
- role: worker
- role: worker
```
export KUBECONFIG="${HOME}/.kube/kind-test-config"
```
```
kind create cluster --config kind-config.yaml --image kindest/node:latest -v4
```
```
make WHAT="test/e2e/e2e.test"
```

Running Conformance Tests With kubetest
These commands are intended to be run within a kubernetes directory, either cloned from source, or extracted from release artifacts such as `kubernetes.tar.gz`. They assume you have a valid golang installation.
```
# ensure kubetest is installed
go get -u k8s.io/test-infra/kubetest
# build test binaries, ginkgo, and kubectl first:
make WHAT="test/e2e/e2e.test vendor/github.com/onsi/ginkgo/ginkgo cmd/kubectl"
# setup for conformance tests
export KUBECONFIG=/path/to/kubeconfig
export KUBERNETES_CONFORMANCE_TEST=y
# Option A: run all conformance tests serially
kubetest --provider=skeleton --test --test_args="--ginkgo.focus=\[Conformance\]"
# Option B: run parallel conformance tests first, then serial conformance tests serially
kubetest --ginkgo-parallel --provider=skeleton --test --test_args="--ginkgo.focus=\[Conformance\] --ginkgo.skip=\[Serial\]"
kubetest --provider=skeleton --test --test_args="--ginkgo.focus=\[Serial\].*\[Conformance\]"

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Kubernetes Conformance Document
For each Kubernetes release, a Conformance Document will be generated that lists all of the tests that comprise the conformance test suite, along with the formal specification of each test. For an example, see the [v1.9 conformance doc] (https://github.com/cncf/k8s-conformance/blob/master/docs/KubeConformance-1.9.md). This document will help people understand what features are being tested without having to look through the testcase's code directly.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Conformance test review board
The conformance subproject uses the [Conformance Test Review board](https://github.com/orgs/kubernetes/projects/9) to track progress of PRs through to approval.
- demotion of tests from conformance
- changes to existing conformance tests
- changes to the conformance criteria or process

New PRs should enter in the To Triage column, and [Conformance test reviewers] (https://github.com/kubernetes/kubernetes/blob/master/test/conformance/testdata/OWNERS) will pick it up from there and move it through the process. New end-to-end tests that are intended to be promoted to conformance tests in the future may be added to this board, but they will not move all the way to the Needs Approval column, as that is intended only for the types of PRs described above.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Promoting Tests to Conformance
- includes information and metadata in the description as follows:
- "/area conformance" on a newline
@kubernetes/cncf-conformance-wg" on a new line, where sig-foo is whichever sig owns this test

--------<PREDICTED_SEGMENT_BOUNDARY>--------

, such as links to reports or dashboards that prove lack of flakiness
- modifies the testcase to use the `framework. than the `framework.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

It()` function all of the required
- run `hack/update-conformance-yaml.sh` which adds the test name to the [conformance.yaml]

--------<PREDICTED_SEGMENT_BOUNDARY>--------

More information [here] (https://github.com/kubernetes/kubernetes/blob/master/test/conformance/README.md)

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Triage column
Once you create the PR, please schedule the additional Windows tests with `/test pull-kubernetes-e2e-aks-engine-azure-windows` to see if any existing tests that pass on Windows are broken by the change.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Conformance Test Comment Metadata
conformance test suite. If the test was modified in subsequent releases then those releases should be included as well (comma separated)
- `Description`: a detailed description of the test. the required behaviour of the Kubernetes components being tested using [RFC2119] (https://tools.ietf.org/html/rfc2119) keywords. This field is meant to be a "specification" of the tested Kubernetes features, as such, it must be detailed enough so that readers can fully understand the aspects of Kubernetes that are being tested without having to read the test's code directly. Additionally, this test should provide a clear distinction between the parts of the test that are there for the purpose of validating Kubernetes rather than simply infrastructure logic that is necessary to setup, or clean up, the test.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Sample Conformance Test
The following snippet of code shows a sample conformance test's metadata:
```
/*
  Release: v1.9
  Testname: Kubelet: log output
  Description: By default the stdout and stderr from the process being executed in a pod MUST be sent to the pod's logs.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

framework.
```

The corresponding portion of the Kubernetes Conformance Document for this test would then look like this:
[Kubelet: log output] (https://github.com/kubernetes/kubernetes/tree/release-1.9/test/e2e_node/kubelet_test.go#L47)
Release : v1.9
By default the stdout and stderr from the process being executed in a pod MUST be sent to the pod's logs.

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Reporting Conformance Test Results
Conformance test results, by provider and releases, can be viewed in the [testgrid conformance dashboard](https://testgrid.k8s.io/conformance-all). If you wish to contribute test results for your provider, please see the [testgrid conformance README] (https://github.com/kubernetes/test-infra/blob/master/testgrid/conformance/README.md)

--------<PREDICTED_SEGMENT_BOUNDARY>--------

Demoting Conformance Tests
Occasionally it may be necessary to remove a test that was added to conformance. Reasons may include but are not limited to:
- The test is discovered to be unreliable and/or includes functionality not intended to be part of conformance

These criteria apply to conformance added in a current release and should follow the same process involved in promoting a test. We may occasionally discover that a conformance test must be demoted in an already released version. This is generally a safe operation for the consumers of conformance - no existing distribution will become less conformant as a result of demoting a test.
- Agreement from conformance approvers that backporting the demotion is consistent with backwards compatibility for the project
- Open the appropriate backport PR following the backport process
- Approval of the backport by the conformance approvers and the release lead

A backported demotion does not imply previously conformant distributions must recertify - those distributions are no less conformant than they were previously. As Kubernetes is a continuously evolving project new patches to previously released versions may tweak behavior in keeping with our commitment to API stability, so we expect true conformance changes in previously released versions to be rare.